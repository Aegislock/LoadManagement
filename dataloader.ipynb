{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9db8dd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Documentation\n",
    "#https://github.com/vishaalagartha/basketball_reference_scraper/blob/master/API.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "52ddc62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import unicodedata\n",
    "\n",
    "sys.path.append('./basketball_reference_scraper/basketball_reference_scraper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d44f11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_season_dates = [\n",
    "    [\"2016-10-25\", \"2017-04-12\"],  # No play-in\n",
    "    [\"2017-10-17\", \"2018-04-11\"],  # No play-in\n",
    "    [\"2018-10-16\", \"2019-04-10\"],  # No play-in\n",
    "    [\"2019-10-22\", \"2020-08-15\"],  # Play-in: Aug 15 (Blazers vs. Grizzlies)\n",
    "    [\"2020-12-22\", \"2021-05-21\"],  # Play-in: May 18–21\n",
    "    [\"2021-10-19\", \"2022-04-15\"],  # Play-in: Apr 12–15\n",
    "    [\"2022-10-18\", \"2023-04-14\"],  # Play-in: Apr 11–14\n",
    "    [\"2023-10-24\", \"2024-04-19\"]   # Play-in: Apr 16–19\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d2be4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle(structure, name):\n",
    "    # Save\n",
    "    with open(f'{name}.pkl', 'wb') as f:\n",
    "        pickle.dump(structure, f)\n",
    "\n",
    "def load_pickle(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        loaded_data = pickle.load(f)\n",
    "        return loaded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0353b9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_name(name):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFKD', name)\n",
    "        if not unicodedata.combining(c)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "257ff169",
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_teams = {\n",
    "    'ATL', 'BOS', 'BRK', 'CHI', 'CHA', 'CLE', 'DAL', 'DEN', 'DET', 'GSW',\n",
    "    'HOU', 'IND', 'LAC', 'LAL', 'MEM', 'MIA', 'MIL', 'MIN', 'NOP', 'NYK',\n",
    "    'OKC', 'ORL', 'PHI', 'PHX', 'POR', 'SAC', 'SAS', 'TOR', 'UTA', 'WAS', 'NBA'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "190dc281",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Teams:\n",
    "    team_city_abbreviations = {\n",
    "        'Atlanta Hawks': 'ATL',\n",
    "        'Boston Celtics': 'BOS',\n",
    "        'Brooklyn Nets': 'BRK',\n",
    "        'Charlotte Bobcats': 'CHA',\n",
    "        'Charlotte Hornets': 'CHO',\n",
    "        'Chicago Bulls': 'CHI',\n",
    "        'Cleveland Cavaliers': 'CLE',\n",
    "        'Dallas Mavericks': 'DAL',\n",
    "        'Denver Nuggets': 'DEN',\n",
    "        'Detroit Pistons': 'DET',\n",
    "        'Golden State Warriors': 'GSW',\n",
    "        'Houston Rockets': 'HOU',\n",
    "        'Indiana Pacers': 'IND',\n",
    "        'LA Clippers': 'LAC',\n",
    "        'Los Angeles Clippers': 'LAC',\n",
    "        'LA Lakers': 'LAL',\n",
    "        'Los Angeles Lakers': 'LAL',\n",
    "        'Memphis Grizzlies': 'MEM',\n",
    "        'Miami Heat': 'MIA',\n",
    "        'Milwaukee Bucks': 'MIL',\n",
    "        'Minnesota Timberwolves': 'MIN',\n",
    "        'New Orleans Pelicans': 'NOP',\n",
    "        'New York Knicks': 'NYK',\n",
    "        'Oklahoma City Thunder': 'OKC',\n",
    "        'Orlando Magic': 'ORL',\n",
    "        'Philadelphia 76ers': 'PHI',\n",
    "        'Phoenix Suns': 'PHO',\n",
    "        'Portland Trail Blazers': 'POR',\n",
    "        'Sacramento Kings': 'SAC',\n",
    "        'San Antonio Spurs': 'SAS',\n",
    "        'Toronto Raptors': 'TOR',\n",
    "        'Utah Jazz': 'UTA',\n",
    "        'Washington Wizards': 'WAS',\n",
    "        'Free Agent': 'NBA'\n",
    "    }\n",
    "\n",
    "    team_abbreviations = {\n",
    "        'Hawks': 'ATL',\n",
    "        'Celtics': 'BOS',\n",
    "        'Nets': 'BRK',\n",
    "        'Bobcats': 'CHA',\n",
    "        'Hornets': 'CHA',\n",
    "        'Bulls': 'CHI',\n",
    "        'Cavaliers': 'CLE',\n",
    "        'Mavericks': 'DAL',\n",
    "        'Nuggets': 'DEN',\n",
    "        'Pistons': 'DET',\n",
    "        'Warriors': 'GSW',\n",
    "        'Rockets': 'HOU',\n",
    "        'Pacers': 'IND',\n",
    "        'Clippers': 'LAC',\n",
    "        'Lakers': 'LAL',\n",
    "        'Grizzlies': 'MEM',\n",
    "        'Heat': 'MIA',\n",
    "        'Bucks': 'MIL',\n",
    "        'Timberwolves': 'MIN',\n",
    "        'Pelicans': 'NOP',\n",
    "        'Knicks': 'NYK',\n",
    "        'Thunder': 'OKC',\n",
    "        'Magic': 'ORL',\n",
    "        '76ers': 'PHI',\n",
    "        'Suns': 'PHX',\n",
    "        'Trail Blazers': 'POR',\n",
    "        'Kings': 'SAC',\n",
    "        'Spurs': 'SAS',\n",
    "        'Raptors': 'TOR',\n",
    "        'Jazz': 'UTA',\n",
    "        'Wizards': 'WAS',\n",
    "        'Free Agent': 'NBA'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d19c354b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from teams import *\n",
    "from players import *\n",
    "from seasons import *\n",
    "from shot_charts import *\n",
    "from box_scores import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af3a1918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_playoff_teams(start_year=2014, end_year=2024):\n",
    "    #Index 0: 2013-2014 season -> Index 10: 2023-2024 Season\n",
    "    playoff_pictures = []\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        playoff_teams = []\n",
    "        year_playoff_scores = get_schedule(year, playoffs=True)\n",
    "        while len(playoff_teams) < 16:\n",
    "            for team in year_playoff_scores['VISITOR']:\n",
    "                if team not in playoff_teams:\n",
    "                    playoff_teams.append(team)\n",
    "        playoff_pictures.append(playoff_teams)\n",
    "    return playoff_pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a470dee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_playoff_rotation_level_players(team_name):\n",
    "    year, team = team_name.split('_')\n",
    "    print(Teams.team_city_abbreviations[team])\n",
    "    roster_playoff_stats = get_roster_stats(Teams.team_city_abbreviations[team], int(year), data_format='PER_GAME', playoffs=True)\n",
    "    return roster_playoff_stats[roster_playoff_stats['MP'] > 10.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26f082b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dictionary_fprlp(teams):\n",
    "    dictionary = {team : [] for team in teams}\n",
    "    for team in teams:\n",
    "        dataframe = find_playoff_rotation_level_players(team)\n",
    "        rotation_players = [player for player in dataframe['PLAYER']]\n",
    "        dictionary[team] = rotation_players\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b63b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nrotation_players = create_dictionary_fprlp(all_playoff_teams)\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "all_study_teams = get_all_playoff_teams()\n",
    "teams_tagged = [\n",
    "    [f\"{2014 + i}_{team}\" for team in team_list]\n",
    "    for i, team_list in enumerate(all_study_teams)\n",
    "]\n",
    "flat_tagged = [team for season in teams_tagged for team in season]\n",
    "save_pickle(flat_tagged, 'playoff_teams')\n",
    "'''\n",
    "\n",
    "'''\n",
    "rotation_players = create_dictionary_fprlp(all_playoff_teams)\n",
    "load_management = log_load_management(rotation_players, injuries_2016_2023, csv_injuries)\n",
    "save_pickle(load_management, 'load_management')\n",
    "'''\n",
    "\n",
    "'''\n",
    "for year in injuries_2016_2023:\n",
    "    injury_list = injuries_2016_2023[year][0]\n",
    "    rest_list = injuries_2016_2023[year][1]\n",
    "\n",
    "    injury_list['Player'] = injury_list['Player'].apply(normalize_name)\n",
    "    rest_list['Player'] = rest_list['Player'].apply(normalize_name)\n",
    "\n",
    "for team in rotation_players:\n",
    "    for index, name in enumerate(rotation_players[team]):\n",
    "        rotation_players[team][index] = normalize_name(name)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "75d2fc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_playoff_teams = load_pickle('playoff_teams.pkl')\n",
    "rotation_players = load_pickle('rotation_players_normalized.pkl')\n",
    "injuries_2016_2023 = load_pickle('seasons_normalized.pkl')\n",
    "#pickle is indexed by starting year\n",
    "#csv is indexed by ending year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1763160",
   "metadata": {},
   "outputs": [],
   "source": [
    "suffixes = ['Jr.', 'Jr', 'Sr.', 'Sr', 'II', 'III', 'IV', 'V']\n",
    "\n",
    "csv_injuries = pd.read_csv('2013-2024_injury_stats.csv')\n",
    "csv_injuries.drop(['Unnamed: 0'], axis=1)\n",
    "csv_injuries['Relinquished'] = csv_injuries['Relinquished'].str.replace(r'\\b(?:' + '|'.join(suffixes) + r')\\b', '', regex=True).str.replace(r'[.,]', '', regex=True).str.strip()\n",
    "csv_injuries['Acquired'] = csv_injuries['Acquired'].str.replace(r'\\b(?:' + '|'.join(suffixes) + r')\\b', '', regex=True).str.replace(r'[.,]', '', regex=True).str.strip()\n",
    "csv_injuries['Team'] = csv_injuries['Team'].str.strip()\n",
    "csv_injuries['Date'] = pd.to_datetime(csv_injuries['Date'])\n",
    "csv_injuries = csv_injuries[csv_injuries['Date'] >= pd.to_datetime('2016-10-25')]\n",
    "csv_injuries = csv_injuries.drop(columns = ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd4190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_management = log_load_management(rotation_players, injuries_2016_2023, csv_injuries)\n",
    "save_pickle(load_management, 'load_management_fix_normalized_3')\n",
    "\n",
    "load_management_stats = load_pickle('load_management_fix_normalized_3.pkl')\n",
    "for team in load_management_stats:\n",
    "    load_management_stats[team] = [pair for pair in load_management_stats[team] if pair[0] != 'Team Totals']\n",
    "save_pickle(load_management_stats, 'load_management_final_fix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "2da5c93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lms = load_pickle('load_management_final_fix.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "15ec5c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Kawhi Leonard', 7),\n",
       " ('Kyle Lowry', 1),\n",
       " ('Pascal Siakam', 0),\n",
       " ('Marc Gasol', 0),\n",
       " ('Danny Green', 0),\n",
       " ('Fred VanVleet', 0),\n",
       " ('Serge Ibaka', 1),\n",
       " ('Norman Powell', 0)]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lms['2019_Toronto Raptors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "64c4a510",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = injuries_2016_2023[2016][0][injuries_2016_2023[2016][0]['Player'] == 'Tony Parker']\n",
    "_, target = parse_days_missed('Tony Parker', df, 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "126e84de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You searched for \"Tony Parker\"\n",
      "17 results found.\n",
      "/players/p/parketo01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tongf\\Documents\\Eclipse\\basketball_reference_scraper/basketball_reference_scraper\\players.py:80: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]\n"
     ]
    }
   ],
   "source": [
    "rest_days = double_check_csv('Tony Parker', target, 2016, csv_injuries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "aa638a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['2016-11-04', '2016-11-10'],\n",
       " ['2016-11-21', '2016-11-22'],\n",
       " ['2016-12-06', '2016-12-07'],\n",
       " ['2016-12-23', '2017-12-07'],\n",
       " ['2017-01-19', '2017-01-26'],\n",
       " ['2017-03-01', '2017-03-02'],\n",
       " ['2017-03-09', '2017-03-17']]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "f38b9f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_all_rests('Tony Parker', 2016, csv_injuries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "0918a99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_rests(player, season, csv_injuries):\n",
    "    index = season - 2016\n",
    "    reg_season_start = pd.to_datetime(reg_season_dates[index][0])\n",
    "    reg_season_end = pd.to_datetime(reg_season_dates[index][1]) #Includes Play-In\n",
    "    season_injury_list = csv_injuries[(csv_injuries['Date'] >= reg_season_start) & (csv_injuries['Date'] <= reg_season_end)]\n",
    "    player_season_injuries = season_injury_list[season_injury_list['Relinquished'].str.contains(player, na=False)]\n",
    "    player_season_injuries = player_season_injuries[(player_season_injuries['Notes'].str.contains('rest')) & (player_season_injuries['Notes'].str.contains('DTD'))]\n",
    "    return len(player_season_injuries)\n",
    "\n",
    "def log_load_management(playoff_rotations, pickle, csv, debug = 0):\n",
    "    dict = {team : [] for team in playoff_rotations.keys()} #List of Tuples\n",
    "    for team in tqdm(playoff_rotations.keys(), desc=\"Processing Teams\"):\n",
    "        year = int(team.split('_')[0])\n",
    "        if year < 2017 or year < debug:\n",
    "            continue\n",
    "        else:\n",
    "            pass\n",
    "        year -= 1 #Indexing for the Pickle\n",
    "        injury_info = pickle[year][0]\n",
    "        rest_info = pickle[year][1]\n",
    "        for player in playoff_rotations[team]:\n",
    "            value = 0\n",
    "            rest_column = rest_info[rest_info['Player'] == player]['Games Missed']\n",
    "            all_rests = find_all_rests(player, year, csv)\n",
    "            if rest_column.empty:\n",
    "                dict[team].append((player, all_rests))\n",
    "            else:\n",
    "                rest_days = int(rest_column.iloc[0]) #Initial Value for Rest Days\n",
    "                _, days_missed_intervals = parse_days_missed(player, injury_info, year)\n",
    "                try:\n",
    "                    rest_days += double_check_csv(player, days_missed_intervals, year, csv)\n",
    "                except Exception as e:\n",
    "                    print(player)\n",
    "                    print(\"Season: \" + str(year) + \"-\" + str(year + 1))\n",
    "                dict[team].append((player, max(rest_days, all_rests)))\n",
    "    return dict\n",
    "            \n",
    "def parse_days_missed(player, injury_info, year):\n",
    "    dm_column = injury_info[injury_info['Player'] == player]['Days Missed'].iloc[0].split(' ')\n",
    "    days_missed = dm_column[0]\n",
    "\n",
    "    dates_missed_strs = dm_column[1:]\n",
    "    dates_missed_arr = [str.split('-') for str in dates_missed_strs]\n",
    "\n",
    "    i = 1\n",
    "    for intervals in dates_missed_arr:\n",
    "        # Assume intervals[0] is a partial date like '01/10' (MM/DD)\n",
    "        try:\n",
    "            # Try parsing normally (if already complete)\n",
    "            parsed = pd.to_datetime(intervals[0], format='%m/%d/%y')\n",
    "            intervals[0] = parsed.strftime('%Y/%m/%d')  # Reformat\n",
    "        except ValueError:\n",
    "            # Handle partial date — needs year appended\n",
    "            partial_date = intervals[0]  # e.g., '01/10'\n",
    "            \n",
    "            # Try both year and year+1, check which one fits the season\n",
    "            try_this_year = f\"{partial_date}/{year}\"\n",
    "            try_next_year = f\"{partial_date}/{year + 1}\"\n",
    "\n",
    "            dt_this_year = pd.to_datetime(try_this_year, format='%m/%d/%Y', errors='coerce')\n",
    "            dt_next_year = pd.to_datetime(try_next_year, format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "            # Season interval\n",
    "            season_start = pd.to_datetime(reg_season_dates[year - 2016][0])\n",
    "            season_end = pd.to_datetime(reg_season_dates[year - 2016][1])\n",
    "\n",
    "            if season_start <= dt_this_year <= season_end:\n",
    "                intervals[0] = dt_this_year.strftime('%Y/%m/%d')\n",
    "            elif season_start <= dt_next_year <= season_end:\n",
    "                intervals[0] = dt_next_year.strftime('%Y/%m/%d')\n",
    "            else:\n",
    "                raise ValueError(f\"Could not determine correct year for interval: {intervals[0]}\")\n",
    "        if i != len(dates_missed_arr):\n",
    "            intervals[1] = intervals[1][:-1] + f\"/{datetime.strptime(intervals[0], '%Y/%m/%d').year}\"\n",
    "        else:\n",
    "            intervals[1] = intervals[1] + f\"/{datetime.strptime(intervals[0], '%Y/%m/%d').year}\"\n",
    "        intervals[1] = datetime.strptime(intervals[1], '%m/%d/%Y').strftime('%Y/%m/%d')\n",
    "        if pd.to_datetime(intervals[1]) < pd.to_datetime(intervals[0]):\n",
    "            intervals[1] = datetime.strptime(intervals[1], '%Y/%m/%d')\n",
    "            # Now add 1 year\n",
    "            if intervals[1] < pd.to_datetime(intervals[0]):\n",
    "                intervals[1] += relativedelta(years=1)\n",
    "            # Then convert back to string\n",
    "            intervals[1] = intervals[1].strftime('%Y-%m-%d')\n",
    "            intervals[0] = intervals[0].replace('/', '-')\n",
    "        intervals[0] = intervals[0].replace('/', '-')\n",
    "        intervals[1] = intervals[1].replace('/', '-')\n",
    "        i += 1\n",
    "\n",
    "    return days_missed, dates_missed_arr\n",
    "\n",
    "def double_check_csv(player, out_dates, year, csv_injuries):\n",
    "    #Index 0 = 2016\n",
    "    game_logs = get_game_logs(player, year + 1)\n",
    "    index = year - 2016\n",
    "    if index < 0:\n",
    "        raise Exception(\"Season cannot be before 2016-2017 season\")\n",
    "    reg_season_start = pd.to_datetime(reg_season_dates[index][0])\n",
    "    reg_season_end = pd.to_datetime(reg_season_dates[index][1]) #Includes Play-In\n",
    "    season_injury_list = csv_injuries[(csv_injuries['Date'] >= reg_season_start) & (csv_injuries['Date'] <= reg_season_end)]\n",
    "    player_season_injuries = season_injury_list[season_injury_list['Relinquished'].str.contains(player, na=False)]\n",
    "    if player_season_injuries.empty:\n",
    "        print(\"No season injuries\")\n",
    "        return 0\n",
    "    player_rests = player_season_injuries[player_season_injuries['Notes'].str.contains('rest')& player_season_injuries['Notes'].str.contains('DTD')] \n",
    "    if player_rests.empty:\n",
    "        print(\"No rests\")\n",
    "        return 0\n",
    "    unaccounted = set()\n",
    "    for rest_date in player_rests['Date']:\n",
    "        accounted = False\n",
    "        for interval in out_dates:\n",
    "            if pd.to_datetime(interval[0]) <= rest_date <= pd.to_datetime(interval[1]):\n",
    "                accounted = True\n",
    "                break\n",
    "        if not accounted:\n",
    "            unaccounted.add(rest_date)\n",
    "\n",
    "    if len(unaccounted) == 0:\n",
    "        print(\"All injuries accounted for\")\n",
    "\n",
    "    # Missing Rest Day(s)\n",
    "    games_rested = 0\n",
    "    for date in unaccounted:\n",
    "        segment = game_logs[game_logs['DATE'] >= date]\n",
    "        for _, row in segment.iterrows():\n",
    "            if pd.isna(row['Gcar']):\n",
    "                games_rested += 1\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "    return games_rested\n",
    "\n",
    "def is_valid_date_format(date_str, fmt='%m/%d/%y'):\n",
    "    try:\n",
    "        datetime.strptime(date_str, fmt)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdecf2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def create_injury_timeline():\n",
    "    df = pd.read_csv('2013-2024_injury_stats.csv')\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df = df.sort_values(by='Date')\n",
    "\n",
    "    df['Relinquished'] = df['Relinquished'].str.strip()\n",
    "    df['Acquired'] = df['Acquired'].str.strip()\n",
    "\n",
    "    injury_timeline = {}\n",
    "    player_to_team = {}  # Track injury origin\n",
    "    last_valid_date = None\n",
    "\n",
    "    zipped_data = zip(df['Date'], df['Team'], df['Acquired'], df['Relinquished'])\n",
    "\n",
    "    for date, team, acquired, relinquished in tqdm(zipped_data, total=len(df), desc=\"Building Injury Timeline\"):\n",
    "        date_str = date.strftime('%Y-%m-%d')\n",
    "\n",
    "        if pd.isna(team):\n",
    "            team_abbreviation = Teams.team_abbreviations['Free Agent']\n",
    "        else:\n",
    "            if team.split()[-1] == 'Blazers':\n",
    "                team_abbreviation = Teams.team_abbreviations['Trail Blazers']\n",
    "            else:\n",
    "                team_abbreviation = Teams.team_abbreviations[team.split()[-1]]\n",
    "\n",
    "        if date_str not in injury_timeline:\n",
    "            if last_valid_date is None:\n",
    "                injury_timeline[date_str] = {nba_team: set() for nba_team in nba_teams}\n",
    "            else:\n",
    "                injury_timeline[date_str] = {\n",
    "                    team: players.copy()\n",
    "                    for team, players in injury_timeline[last_valid_date].items()\n",
    "                }\n",
    "        last_valid_date = date_str\n",
    "\n",
    "        # Add player to injury list\n",
    "        if pd.isna(acquired) and pd.notna(relinquished):\n",
    "            injury_timeline[date_str][team_abbreviation].add(relinquished)\n",
    "            player_to_team[relinquished] = team_abbreviation\n",
    "\n",
    "        # Player returns\n",
    "        elif pd.notna(acquired) and pd.isna(relinquished):\n",
    "            injury_team = player_to_team.get(acquired, team_abbreviation)\n",
    "            if acquired in injury_timeline[last_valid_date][injury_team]:\n",
    "                injury_timeline[date_str][injury_team].discard(acquired)\n",
    "\n",
    "    return injury_timeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
